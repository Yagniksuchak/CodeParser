commit 1f234839b172475bd78b359b993f449909240a01
Author: Liu Liu <i@liuliu.me>
Date:   2014-07-17

    add verify for fc pass. fixed CPU version training when we cached weights

diff --git a/bin/cuda/cwc-verify.c b/bin/cuda/cwc-verify.c
index 970f931..64a4f07 100644
--- a/bin/cuda/cwc-verify.c
+++ b/bin/cuda/cwc-verify.c
@@ -3,319 +3,319 @@
 
-void cwc_bench_runtime(ccv_convnet_t* convnet, ccv_array_t* categorizeds, ccv_convnet_train_param_t params);
+void cwc_verify_runtime(ccv_convnet_t* convnet, ccv_array_t* categorizeds, ccv_convnet_train_param_t params);
 
 int main(int argc, char** argv)
 {
 	ccv_enable_default_cache();
 	assert(argc == 2);
 	FILE *r = fopen(argv[1], "r");
 	char* file = (char*)malloc(1024);
 	ccv_array_t* categorizeds = ccv_array_new(sizeof(ccv_categorized_t), 64, 0);
 	size_t len = 1024;
 	ssize_t read;
 	while ((read = getline(&file, &len, r)) != -1)
 	{
 		while(read > 1 && isspace(file[read - 1]))
 			read--;
 		file[read] = 0;
 		ccv_file_info_t input;
 		input.filename = (char*)ccmalloc(1024);
 		strncpy(input.filename, file, 1024);
 		ccv_categorized_t categorized = ccv_categorized(0, 0, &input);
 		ccv_array_push(categorizeds, &categorized);
 	}
 	fclose(r);
 	free(file);
 	ccv_convnet_layer_param_t params[11] = {
 		// first layer (convolutional => max pool => rnorm)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 0,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 225,
 					.cols = 225,
 					.channels = 3,
 					.partition = 1,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 96,
 					.strides = 2,
 					.border = 1,
 					.rows = 7,
 					.cols = 7,
 					.channels = 3,
 					.partition = 2,
 				},
 			},
 		},
 		{
 			.type = CCV_CONVNET_AVERAGE_POOL,
 			.input = {
 				.matrix = {
 					.rows = 111,
 					.cols = 111,
 					.channels = 96,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.pool = {
 					.strides = 2,
 					.size = 3,
 					.border = 0,
 				},
 			},
 		},
 		// second layer (convolutional => max pool => rnorm)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 55,
 					.cols = 55,
 					.channels = 96,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 256,
 					.strides = 2,
 					.border = 1,
 					.rows = 5,
 					.cols = 5,
 					.channels = 96,
 					.partition = 2,
 				},
 			},
 		},
 		{
 			.type = CCV_CONVNET_AVERAGE_POOL,
 			.input = {
 				.matrix = {
 					.rows = 27,
 					.cols = 27,
 					.channels = 256,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.pool = {
 					.strides = 2,
 					.size = 3,
 					.border = 0,
 				},
 			},
 		},
 		// third layer (convolutional)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 0,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 13,
 					.cols = 13,
 					.channels = 256,
 					.partition = 1,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 384,
 					.strides = 1,
 					.border = 1,
 					.rows = 3,
 					.cols = 3,
 					.channels = 256,
 					.partition = 2,
 				},
 			},
 		},
 		// fourth layer (convolutional)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 13,
 					.cols = 13,
 					.channels = 384,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 384,
 					.strides = 1,
 					.border = 1,
 					.rows = 3,
 					.cols = 3,
 					.channels = 384,
 					.partition = 2,
 				},
 			},
 		},
 		// fifth layer (convolutional => max pool)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 13,
 					.cols = 13,
 					.channels = 384,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 256,
 					.strides = 1,
 					.border = 1,
 					.rows = 3,
 					.cols = 3,
 					.channels = 384,
 					.partition = 2,
 				},
 			},
 		},
 		{
 			.type = CCV_CONVNET_MAX_POOL,
 			.input = {
 				.matrix = {
 					.rows = 13,
 					.cols = 13,
 					.channels = 256,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.pool = {
 					.strides = 2,
 					.size = 3,
 					.border = 0,
 				},
 			},
 		},
 		// sixth layer (full connect)
 		{
 			.type = CCV_CONVNET_FULL_CONNECT,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 6,
 					.cols = 6,
 					.channels = 256,
 					.partition = 1,
 				},
 				.node = {
 					.count = 6 * 6 * 256,
 				},
 			},
 			.output = {
 				.full_connect = {
 					.relu = 1,
 					.count = 4096,
 				},
 			},
 		},
 		// seventh layer (full connect)
 		{
 			.type = CCV_CONVNET_FULL_CONNECT,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 4096,
 					.cols = 1,
 					.channels = 1,
 					.partition = 1,
 				},
 				.node = {
 					.count = 4096,
 				},
 			},
 			.output = {
 				.full_connect = {
 					.relu = 1,
 					.count = 4096,
 				},
 			},
 		},
 		// eighth layer (full connect)
 		{
 			.type = CCV_CONVNET_FULL_CONNECT,
 			.bias = 0,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 4096,
 					.cols = 1,
 					.channels = 1,
 					.partition = 1,
 				},
 				.node = {
 					.count = 4096,
 				},
 			},
 			.output = {
 				.full_connect = {
 					.relu = 0,
 					.count = 1000,
 				},
 			},
 		},
 	};
 	ccv_convnet_t* convnet = ccv_convnet_new(1, ccv_size(225, 225), params, sizeof(params) / sizeof(ccv_convnet_layer_param_t));
 	ccv_convnet_verify(convnet, 1000);
 	ccv_convnet_layer_train_param_t layer_params[11];
 	memset(layer_params, 0, sizeof(layer_params));
 	int i;
 	for (i = 0; i < 11; i++)
 	{
 		layer_params[i].w.decay = 0.005;
 		layer_params[i].w.learn_rate = 0.0005;
 		layer_params[i].w.momentum = 0.9;
 		layer_params[i].bias.decay = 0;
 		layer_params[i].bias.learn_rate = 0.001;
 		layer_params[i].bias.momentum = 0.9;
 	}
 	ccv_convnet_train_param_t train_params = {
 		.max_epoch = 100,
 		.mini_batch = 128,
 		.dual_device = 0,
 		.layer_params = layer_params,
 	};
 	for (i = 0; i < 128; i++)
 	{
 		ccv_categorized_t* categorized = (ccv_categorized_t*)ccv_array_get(categorizeds, i);
 		ccv_dense_matrix_t* image = 0;
 		ccv_read(categorized->file.filename, &image, CCV_IO_ANY_FILE | CCV_IO_RGB_COLOR);
 		ccv_dense_matrix_t* b = 0;
 		if (image->rows > 225 && image->cols > 225)
 			ccv_resample(image, &b, 0, ccv_max(225, (int)(image->rows * 225.0 / image->cols + 0.5)), ccv_max(225, (int)(image->cols * 225.0 / image->rows + 0.5)), CCV_INTER_AREA);
 		else if (image->rows < 225 || image->cols < 225)
 			ccv_resample(image, &b, 0, ccv_max(225, (int)(image->rows * 225.0 / image->cols + 0.5)), ccv_max(225, (int)(image->cols * 225.0 / image->rows + 0.5)), CCV_INTER_CUBIC);
 		else
 			b = image;
 		if (b != image)
 			ccv_matrix_free(image);
 		ccv_dense_matrix_t* c = 0;
 		ccv_slice(b, (ccv_matrix_t**)&c, CCV_32F, 0, 0, 225, 225);
 		ccv_matrix_free(b);
 		categorized->type = CCV_CATEGORIZED_DENSE_MATRIX;
 		categorized->matrix = c;
 	}
-	cwc_bench_runtime(convnet, categorizeds, train_params);
+	cwc_verify_runtime(convnet, categorizeds, train_params);
 	ccv_disable_cache();
 	return 0;
 }
diff --git a/bin/image-net.c b/bin/image-net.c
index 37ca30c..231f94a 100644
--- a/bin/image-net.c
+++ b/bin/image-net.c
@@ -24,409 +24,409 @@ void exit_with_help(void)
 int main(int argc, char** argv)
 {
 	static struct option image_net_options[] = {
 		/* help */
 		{"help", 0, 0, 0},
 		/* required parameters */
 		{"train-list", 1, 0, 0},
 		{"test-list", 1, 0, 0},
 		{"working-dir", 1, 0, 0},
 		/* optional parameters */
 		{"base-dir", 1, 0, 0},
 		{"max-epoch", 1, 0, 0},
 		{"iterations", 1, 0, 0},
 		{0, 0, 0, 0}
 	};
 	char* train_list = 0;
 	char* test_list = 0;
 	char* working_dir = 0;
 	char* base_dir = 0;
 	ccv_convnet_train_param_t train_params = {
 		.max_epoch = 100,
 		.mini_batch = 128,
 		.iterations = 20000,
 		.dual_device = 0,
 		.symmetric = 1,
 		.color_gain = 0.001,
 	};
 	int i, c;
 	while (getopt_long_only(argc, argv, "", image_net_options, &c) != -1)
 	{
 		switch (c)
 		{
 			case 0:
 				exit_with_help();
 			case 1:
 				train_list = optarg;
 				break;
 			case 2:
 				test_list = optarg;
 				break;
 			case 3:
 				working_dir = optarg;
 				break;
 			case 4:
 				base_dir = optarg;
 				break;
 			case 5:
 				train_params.max_epoch = atoi(optarg);
 				break;
 			case 6:
 				train_params.iterations = atoi(optarg);
 				break;
 		}
 	}
 	if (!train_list || !test_list || !working_dir)
 		exit_with_help();
 	ccv_enable_default_cache();
 	FILE *r0 = fopen(train_list, "r");
 	assert(r0 && "train-list doesn't exists");
 	FILE* r1 = fopen(test_list, "r");
 	assert(r1 && "test-list doesn't exists");
 	char* file = (char*)malloc(1024);
 	int dirlen = (base_dir != 0) ? strlen(base_dir) + 1 : 0;
 	ccv_array_t* categorizeds = ccv_array_new(sizeof(ccv_categorized_t), 64, 0);
 	while (fscanf(r0, "%d %s", &c, file) != EOF)
 	{
 		char* filename = (char*)ccmalloc(1024);
 		if (base_dir != 0)
 		{
 			strncpy(filename, base_dir, 1024);
 			filename[dirlen - 1] = '/';
 		}
 		strncpy(filename + dirlen, file, 1024 - dirlen);
 		ccv_file_info_t file_info = {
 			.filename = filename,
 		};
 		// imageNet's category class starts from 1, thus, minus 1 to get 0-index
 		ccv_categorized_t categorized = ccv_categorized(c - 1, 0, &file_info);
 		ccv_array_push(categorizeds, &categorized);
 	}
 	fclose(r0);
 	ccv_array_t* tests = ccv_array_new(sizeof(ccv_categorized_t), 64, 0);
 	while (fscanf(r1, "%d %s", &c, file) != EOF)
 	{
 		char* filename = (char*)ccmalloc(1024);
 		if (base_dir != 0)
 		{
 			strncpy(filename, base_dir, 1024);
 			filename[dirlen - 1] = '/';
 		}
 		strncpy(filename + dirlen, file, 1024 - dirlen);
 		ccv_file_info_t file_info = {
 			.filename = filename,
 		};
 		// imageNet's category class starts from 1, thus, minus 1 to get 0-index
 		ccv_categorized_t categorized = ccv_categorized(c - 1, 0, &file_info);
 		ccv_array_push(tests, &categorized);
 	}
 	fclose(r1);
 	free(file);
 	ccv_convnet_layer_param_t params[13] = {
 		// first layer (convolutional => max pool => rnorm)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 0,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 225,
 					.cols = 225,
 					.channels = 3,
 					.partition = 1,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 96,
 					.strides = 2,
 					.border = 1,
 					.rows = 7,
 					.cols = 7,
 					.channels = 3,
 					.partition = 2,
 				},
 			},
 		},
 		{
 			.type = CCV_CONVNET_LOCAL_RESPONSE_NORM,
 			.input = {
 				.matrix = {
 					.rows = 111,
 					.cols = 111,
 					.channels = 96,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.rnorm = {
 					.size = 5,
 					.kappa = 2,
 					.alpha = 1e-4,
 					.beta = 0.75,
 				},
 			},
 		},
 		{
 			.type = CCV_CONVNET_MAX_POOL,
 			.input = {
 				.matrix = {
 					.rows = 111,
 					.cols = 111,
 					.channels = 96,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.pool = {
 					.strides = 2,
 					.size = 3,
 					.border = 0,
 				},
 			},
 		},
 		// second layer (convolutional => max pool => rnorm)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 55,
 					.cols = 55,
 					.channels = 96,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 256,
 					.strides = 2,
 					.border = 1,
 					.rows = 5,
 					.cols = 5,
 					.channels = 96,
 					.partition = 2,
 				},
 			},
 		},
 		{
 			.type = CCV_CONVNET_LOCAL_RESPONSE_NORM,
 			.input = {
 				.matrix = {
 					.rows = 27,
 					.cols = 27,
 					.channels = 256,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.rnorm = {
 					.size = 5,
 					.kappa = 2,
 					.alpha = 1e-4,
 					.beta = 0.75,
 				},
 			},
 		},
 		{
 			.type = CCV_CONVNET_MAX_POOL,
 			.input = {
 				.matrix = {
 					.rows = 27,
 					.cols = 27,
 					.channels = 256,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.pool = {
 					.strides = 2,
 					.size = 3,
 					.border = 0,
 				},
 			},
 		},
 		// third layer (convolutional)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 0,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 13,
 					.cols = 13,
 					.channels = 256,
 					.partition = 1,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 384,
 					.strides = 1,
 					.border = 1,
 					.rows = 3,
 					.cols = 3,
 					.channels = 256,
 					.partition = 2,
 				},
 			},
 		},
 		// fourth layer (convolutional)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 13,
 					.cols = 13,
 					.channels = 384,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 384,
 					.strides = 1,
 					.border = 1,
 					.rows = 3,
 					.cols = 3,
 					.channels = 384,
 					.partition = 2,
 				},
 			},
 		},
 		// fifth layer (convolutional => max pool)
 		{
 			.type = CCV_CONVNET_CONVOLUTIONAL,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 13,
 					.cols = 13,
 					.channels = 384,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.convolutional = {
 					.count = 256,
 					.strides = 1,
 					.border = 1,
 					.rows = 3,
 					.cols = 3,
 					.channels = 384,
 					.partition = 2,
 				},
 			},
 		},
 		{
 			.type = CCV_CONVNET_MAX_POOL,
 			.input = {
 				.matrix = {
 					.rows = 13,
 					.cols = 13,
 					.channels = 256,
 					.partition = 2,
 				},
 			},
 			.output = {
 				.pool = {
 					.strides = 2,
 					.size = 3,
 					.border = 0,
 				},
 			},
 		},
 		// sixth layer (full connect)
 		{
 			.type = CCV_CONVNET_FULL_CONNECT,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
 					.rows = 6,
 					.cols = 6,
 					.channels = 256,
 					.partition = 1,
 				},
 				.node = {
 					.count = 6 * 6 * 256,
 				},
 			},
 			.output = {
 				.full_connect = {
 					.relu = 1,
-					.count = 4096,
+					.count = 2048,
 				},
 			},
 		},
 		// seventh layer (full connect)
 		{
 			.type = CCV_CONVNET_FULL_CONNECT,
 			.bias = 1,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
-					.rows = 4096,
+					.rows = 2048,
 					.cols = 1,
 					.channels = 1,
 					.partition = 1,
 				},
 				.node = {
-					.count = 4096,
+					.count = 2048,
 				},
 			},
 			.output = {
 				.full_connect = {
 					.relu = 1,
-					.count = 4096,
+					.count = 2048,
 				},
 			},
 		},
 		// eighth layer (full connect)
 		{
 			.type = CCV_CONVNET_FULL_CONNECT,
 			.bias = 0,
 			.sigma = 0.01,
 			.input = {
 				.matrix = {
-					.rows = 4096,
+					.rows = 2048,
 					.cols = 1,
 					.channels = 1,
 					.partition = 1,
 				},
 				.node = {
-					.count = 4096,
+					.count = 2048,
 				},
 			},
 			.output = {
 				.full_connect = {
 					.relu = 0,
 					.count = 1000,
 				},
 			},
 		},
 	};
 	ccv_convnet_t* convnet = ccv_convnet_new(1, ccv_size(257, 257), params, sizeof(params) / sizeof(ccv_convnet_layer_param_t));
 	ccv_convnet_verify(convnet, 1000);
 	ccv_convnet_layer_train_param_t layer_params[13];
 	memset(layer_params, 0, sizeof(layer_params));
 	for (i = 0; i < 13; i++)
 	{
 		layer_params[i].w.decay = 0.0005;
-		layer_params[i].w.learn_rate = 0.02;
+		layer_params[i].w.learn_rate = 0.01;
 		layer_params[i].w.momentum = 0.9;
 		layer_params[i].bias.decay = 0;
-		layer_params[i].bias.learn_rate = 0.02;
+		layer_params[i].bias.learn_rate = 0.01;
 		layer_params[i].bias.momentum = 0.9;
 	}
 	layer_params[10].dor = 0.5;
 	layer_params[11].dor = 0.5;
 	train_params.layer_params = layer_params;
 	ccv_convnet_supervised_train(convnet, categorizeds, tests, working_dir, train_params);
 	ccv_convnet_free(convnet);
 	ccv_disable_cache();
 	return 0;
 }
diff --git a/lib/ccv_convnet.c b/lib/ccv_convnet.c
index 973a58e..42c50c3 100644
--- a/lib/ccv_convnet.c
+++ b/lib/ccv_convnet.c
@@ -23,98 +23,104 @@
 ccv_convnet_t* ccv_convnet_new(int use_cwc_accel, ccv_size_t input, ccv_convnet_layer_param_t params[], int count)
 {
-	ccv_convnet_t* convnet = (ccv_convnet_t*)ccmalloc(sizeof(ccv_convnet_t) + sizeof(ccv_convnet_layer_t) * count + sizeof(ccv_dense_matrix_t*) * count * 2 + sizeof(ccv_dense_matrix_t*) * (count - 1));
+	ccv_convnet_t* convnet = (ccv_convnet_t*)ccmalloc(sizeof(ccv_convnet_t) + sizeof(ccv_convnet_layer_t) * count + sizeof(ccv_dense_matrix_t*) * count * 2);
 	convnet->use_cwc_accel = use_cwc_accel;
 #ifdef HAVE_GSL
 	gsl_rng_env_setup();
 	gsl_rng* rng = gsl_rng_alloc(gsl_rng_default);
 	gsl_rng_set(rng, (unsigned long int)convnet);
 #endif
 	convnet->reserved = 0;
 	convnet->layers = (ccv_convnet_layer_t*)(convnet + 1);
 	convnet->acts = (ccv_dense_matrix_t**)(convnet->layers + count);
 	memset(convnet->acts, 0, sizeof(ccv_dense_matrix_t*) * count);
 	convnet->denoms = (ccv_dense_matrix_t**)(convnet->acts + count);
 	memset(convnet->denoms, 0, sizeof(ccv_dense_matrix_t*) * count);
 	convnet->count = count;
 	convnet->input = input;
 	convnet->rows = params[0].input.matrix.rows;
 	convnet->cols = params[0].input.matrix.cols;
 	convnet->channels = params[0].input.matrix.channels;
 	convnet->mean_activity = ccv_dense_matrix_new(convnet->input.height, convnet->input.width, convnet->channels | CCV_32F, 0, 0);
 	ccv_zero(convnet->mean_activity);
 	ccv_convnet_layer_t* layers = convnet->layers;
 	int i, j;
 	for (i = 0; i < count; i++)
 	{
 		layers[i].type = params[i].type;
 		layers[i].input = params[i].input;
 		layers[i].net = params[i].output;
 		layers[i].reserved = 0;
 		switch (params[i].type)
 		{
 			case CCV_CONVNET_CONVOLUTIONAL:
 				assert(params[i].input.matrix.channels % params[i].input.matrix.partition == 0);
 				assert(params[i].output.convolutional.count % params[i].output.convolutional.partition == 0);
 				assert(params[i].output.convolutional.partition % params[i].input.matrix.partition == 0);
 				assert(params[i].output.convolutional.partition >= params[i].input.matrix.partition);
 				layers[i].wnum = params[i].output.convolutional.rows * params[i].output.convolutional.cols * params[i].output.convolutional.channels / params[i].input.matrix.partition * params[i].output.convolutional.count;
 				layers[i].w = (float*)ccmalloc(sizeof(float) * (layers[i].wnum + params[i].output.convolutional.count));
 				layers[i].bias = layers[i].w + layers[i].wnum;
 #ifdef HAVE_GSL
 				for (j = 0; j < layers[i].wnum; j++)
 					layers[i].w[j] = gsl_ran_gaussian(rng, params[i].sigma);
 #else
 				for (j = 0; j < layers[i].wnum; j++)
 					layers[i].w[j] = 0;
 #endif
 				for (j = 0; j < params[i].output.convolutional.count; j++)
 					layers[i].bias[j] = params[i].bias;
 				break;
 			case CCV_CONVNET_FULL_CONNECT:
 				layers[i].wnum = params[i].input.node.count * params[i].output.full_connect.count;
 				layers[i].w = (float*)ccmalloc(sizeof(float) * (layers[i].wnum + params[i].output.full_connect.count));
 				layers[i].bias = layers[i].w + layers[i].wnum;
 #ifdef HAVE_GSL
 				for (j = 0; j < layers[i].wnum; j++)
 					layers[i].w[j] = gsl_ran_gaussian(rng, params[i].sigma);
 #else
 				for (j = 0; j < layers[i].wnum; j++)
 					layers[i].w[j] = 0;
 #endif
 				for (j = 0; j < params[i].output.full_connect.count; j++)
 					layers[i].bias[j] = params[i].bias;
 				break;
 			default:
 				layers[i].wnum = 0;
 				layers[i].w = 0;
 				layers[i].bias = 0;
 				break;
 		}
 	}
 #ifdef HAVE_GSL
 	gsl_rng_free(rng);
 #endif
 	return convnet;
 }
 
 int ccv_convnet_verify(ccv_convnet_t* convnet, int output)
 {
 	int i, out_rows, out_cols, out_partition;
 	if (convnet->count < 1)
 		return -1;
+	// the last layer has to be full connect
+	if (convnet->layers[convnet->count - 1].type != CCV_CONVNET_FULL_CONNECT)
+		return -1;
+	// you cannot enable relu on the last layer
+	if (convnet->layers[convnet->count - 1].net.full_connect.relu)
+		return -1;
 	for (i = 0; i < convnet->count; i++)
 	{
 		ccv_convnet_layer_t* layer = convnet->layers + i;
 		if (i > 0 && (out_rows != layer->input.matrix.rows || out_cols != layer->input.matrix.cols))
 			return -1;
 		_ccv_convnet_layer_derive_output(layer, layer->input.matrix.rows, layer->input.matrix.cols, &out_rows, &out_cols, &out_partition);
 	}
 	if (out_rows * out_cols != output)
 		return -1;
 	return 0;
 }
 
 #endif
 
 #if defined(HAVE_SSE2) || defined(HAVE_NEON)
 
@@ -1113,50 +1119,55 @@ static void _ccv_convnet_propagate_loss(ccv_convnet_t* convnet, ccv_dense_matrix
 
-static void _ccv_convnet_update(ccv_convnet_t* convnet, ccv_convnet_t* momentum, ccv_convnet_t* update_params, ccv_convnet_layer_train_param_t* layer_params)
+static void _ccv_convnet_update(ccv_convnet_t* convnet, int batch, ccv_convnet_t* momentum, ccv_convnet_t* update_params, ccv_convnet_layer_train_param_t* layer_params)
 {
 	int i, j;
+	float learn_rate;
 	for (i = 0; i < convnet->count; i++)
 		switch (update_params->layers[i].type)
 		{
 			case CCV_CONVNET_CONVOLUTIONAL:
 			{
 				float* w = convnet->layers[i].w;
 				float* vw = momentum->layers[i].w;
 				float* dw = update_params->layers[i].w;
+				learn_rate = layer_params[i].w.learn_rate / batch;
 				for (j = 0; j < convnet->layers[i].wnum; j++)
 				{
-					vw[j] = layer_params[i].w.momentum * vw[j] - layer_params[i].w.decay * layer_params[i].w.learn_rate * w[j] + layer_params[i].w.learn_rate * dw[j];
+					vw[j] = layer_params[i].w.momentum * vw[j] - layer_params[i].w.decay * layer_params[i].w.learn_rate * w[j] + learn_rate * dw[j];
 					w[j] += vw[j];
 				}
 				float* bias = convnet->layers[i].bias;
 				float* vbias = momentum->layers[i].bias;
 				float* dbias = update_params->layers[i].bias;
+				learn_rate = layer_params[i].bias.learn_rate / batch;
 				for (j = 0; j < convnet->layers[i].net.convolutional.count; j++)
 				{
-					vbias[j] = layer_params[i].bias.momentum * vbias[j] - layer_params[i].bias.decay * layer_params[i].bias.learn_rate * bias[j] + layer_params[i].bias.learn_rate * dbias[j];
+					vbias[j] = layer_params[i].bias.momentum * vbias[j] - layer_params[i].bias.decay * layer_params[i].bias.learn_rate * bias[j] + learn_rate * dbias[j];
 					bias[j] += vbias[j];
 				}
 				break;
 			}
 			case CCV_CONVNET_FULL_CONNECT:
 			{
 				float* w = convnet->layers[i].w;
 				float* vw = momentum->layers[i].w;
 				float* dw = update_params->layers[i].w;
+				learn_rate = layer_params[i].w.learn_rate / batch;
 				for (j = 0; j < convnet->layers[i].wnum; j++)
 				{
-					vw[j] = layer_params[i].w.momentum * vw[j] - layer_params[i].w.decay * layer_params[i].w.learn_rate * w[j] + layer_params[i].w.learn_rate * dw[j];
+					vw[j] = layer_params[i].w.momentum * vw[j] - layer_params[i].w.decay * layer_params[i].w.learn_rate * w[j] + learn_rate * dw[j];
 					w[j] += vw[j];
 				}
 				float* bias = convnet->layers[i].bias;
 				float* vbias = momentum->layers[i].bias;
 				float* dbias = update_params->layers[i].bias;
+				learn_rate = layer_params[i].bias.learn_rate / batch;
 				for (j = 0; j < convnet->layers[i].net.full_connect.count; j++)
 				{
-					vbias[j] = layer_params[i].bias.momentum * vbias[j] - layer_params[i].bias.decay * layer_params[i].bias.learn_rate * bias[j] + layer_params[i].bias.learn_rate * dbias[j];
+					vbias[j] = layer_params[i].bias.momentum * vbias[j] - layer_params[i].bias.decay * layer_params[i].bias.learn_rate * bias[j] + learn_rate * dbias[j];
 					bias[j] += vbias[j];
 				}
 				break;
 			}
 		}
 }
 
@@ -1181,43 +1192,44 @@ static void _ccv_convnet_update_zero(ccv_convnet_t* update_params)
 static ccv_convnet_t* _ccv_convnet_update_new(ccv_convnet_t* convnet)
 {
 	ccv_convnet_t* update_params = (ccv_convnet_t*)ccmalloc(sizeof(ccv_convnet_t) + sizeof(ccv_convnet_layer_t) * convnet->count + sizeof(ccv_dense_matrix_t*) * convnet->count);
 	update_params->reserved = 0;
 	update_params->layers = (ccv_convnet_layer_t*)(update_params + 1);
 	update_params->acts = (ccv_dense_matrix_t**)(update_params->layers + convnet->count);
 	memset(update_params->acts, 0, sizeof(ccv_dense_matrix_t*) * convnet->count);
 	update_params->denoms = 0;
 	update_params->input = convnet->input;
 	update_params->rows = convnet->rows;
 	update_params->cols = convnet->cols;
 	update_params->count = convnet->count;
 	update_params->channels = convnet->channels;
 	update_params->mean_activity = 0;
 	int i;
 	for (i = 0; i < convnet->count; i++)
 	{
 		update_params->layers[i].type = convnet->layers[i].type;
+		update_params->layers[i].input = convnet->layers[i].input;
 		update_params->layers[i].net = convnet->layers[i].net;
 		update_params->layers[i].wnum = convnet->layers[i].wnum;
 		update_params->layers[i].reserved = 0;
 		switch (update_params->layers[i].type)
 		{
 			case CCV_CONVNET_CONVOLUTIONAL:
-				update_params->layers[i].w = (float*)cccalloc(sizeof(float), update_params->layers[i].wnum + update_params->layers[i].net.convolutional.count);
+				update_params->layers[i].w = (float*)cccalloc(update_params->layers[i].wnum + update_params->layers[i].net.convolutional.count, sizeof(float));
 				update_params->layers[i].bias = update_params->layers[i].w + update_params->layers[i].wnum;
 				break;
 			case CCV_CONVNET_FULL_CONNECT:
 				assert(update_params->layers[i].wnum % update_params->layers[i].net.full_connect.count == 0);
-				update_params->layers[i].w = (float*)cccalloc(sizeof(float), update_params->layers[i].wnum + update_params->layers[i].net.full_connect.count);
+				update_params->layers[i].w = (float*)cccalloc(update_params->layers[i].wnum + update_params->layers[i].net.full_connect.count, sizeof(float));
 				update_params->layers[i].bias = update_params->layers[i].w + update_params->layers[i].wnum;
 				break;
 			case CCV_CONVNET_LOCAL_RESPONSE_NORM:
 			case CCV_CONVNET_MAX_POOL:
 			case CCV_CONVNET_AVERAGE_POOL:
 				update_params->layers[i].w = 0;
 				update_params->layers[i].bias = 0;
 				break;
 		}
 	}
 	return update_params;
 }
 
@@ -1244,95 +1256,97 @@ static void _ccv_convnet_compute_softmax(ccv_dense_matrix_t* a, ccv_dense_matrix
 static void _ccv_convnet_classify(ccv_convnet_t* convnet, ccv_dense_matrix_t** a, int* labels, int batch)
 {
 	assert(batch == 1);
 	ccv_convnet_encode(convnet, a, convnet->acts + convnet->count - 1, 1);
 	int i, c = 0;
 	ccv_dense_matrix_t* b = convnet->acts[convnet->count - 1];
-	int maxc = b->data.f32[0];
+	float maxc = b->data.f32[0];
 	for (i = 1; i < b->rows; i++)
 		if (b->data.f32[i] > maxc)
 			maxc = b->data.f32[i], c = i;
 	labels[0] = c;
 }
 
 #endif
 
 #ifndef CASE_TESTS
 
 void ccv_convnet_supervised_train(ccv_convnet_t* convnet, ccv_array_t* categorizeds, ccv_array_t* tests, const char* filename, ccv_convnet_train_param_t params)
 {
 #ifdef HAVE_GSL
 #ifdef HAVE_CUDA
 	if (convnet->use_cwc_accel)
 		cwc_convnet_supervised_train(convnet, categorizeds, tests, filename, params);
 	else {
 #endif
 	int i, j, t;
 	gsl_rng_env_setup();
 	gsl_rng* rng = gsl_rng_alloc(gsl_rng_default);
 	int aligned_padding = categorizeds->rnum % params.mini_batch;
 	int aligned_rnum = categorizeds->rnum - aligned_padding;
 	int* idx = (int*)ccmalloc(sizeof(int) * (categorizeds->rnum + aligned_padding));
 	for (i = 0; i < categorizeds->rnum; i++)
 		idx[i] = i;
 	gsl_ran_shuffle(rng, idx, categorizeds->rnum, sizeof(int));
 	// the last layer has to be full connect, thus we can use it as softmax layer
 	assert(convnet->layers[convnet->count - 1].type == CCV_CONVNET_FULL_CONNECT);
 	int category_count = convnet->layers[convnet->count - 1].net.full_connect.count;
 	ccv_convnet_t* update_params = _ccv_convnet_update_new(convnet);
 	ccv_convnet_t* momentum = _ccv_convnet_update_new(convnet);
 	for (t = 0; t < params.max_epoch; t++)
 	{
 		for (i = 0; i < aligned_rnum; i++)
 		{
 			// dropout the first hidden layer
 			ccv_categorized_t* categorized = (ccv_categorized_t*)ccv_array_get(categorizeds, idx[i]);
 			ccv_convnet_encode(convnet, &categorized->matrix, convnet->acts + convnet->count - 1, 1);
 			ccv_dense_matrix_t* softmax = convnet->acts[convnet->count - 1];
 			float* dloss = softmax->data.f32;
 			_ccv_convnet_compute_softmax(softmax, &softmax, 0);
 			assert(softmax->rows == category_count && softmax->cols == 1);
 			// this mashes softmax and logistic regression together
 			// also, it gives you -D[loss w.r.t. to x_i] (note the negative sign)
 			for (j = 0; j < category_count; j++)
 				dloss[j] = (j == categorized->c) - dloss[j];
 			_ccv_convnet_propagate_loss(convnet, categorized->matrix, softmax, update_params);
 			if ((i + 1) % params.mini_batch == 0)
 			{
 				FLUSH(" - at epoch %03d / %d => stochastic gradient descent at %d / %d", t + 1, params.max_epoch, (i + 1) / params.mini_batch, aligned_rnum / params.mini_batch);
 				// update weights
-				_ccv_convnet_update(convnet, momentum, update_params, params.layer_params);
+				_ccv_convnet_update(convnet, params.mini_batch, momentum, update_params, params.layer_params);
 				_ccv_convnet_update_zero(update_params);
+				// compact the convnet to avoid any staled temporary resource
+				ccv_convnet_compact(convnet);
 			}
 		}
 		int miss = 0;
 		for (i = 0; i < tests->rnum; i++)
 		{
 			FLUSH(" - at epoch %03d / %d => going through %d / %d for tests", t + 1, params.max_epoch, i + 1, tests->rnum);
 			ccv_categorized_t* test = (ccv_categorized_t*)ccv_array_get(tests, i);
 			int c = 0;
 			_ccv_convnet_classify(convnet, &test->matrix, &c, 1);
 			if (c != test->c)
 				++miss;
 		}
 		FLUSH(" - at epoch %03d / %d => with miss rate %.2f%%\n", t + 1, params.max_epoch, miss * 100.0f / tests->rnum);
 		if (t + 1 < params.max_epoch)
 		{
 			// reshuffle the parts we visited and move the rest to the beginning
 			memcpy(idx + categorizeds->rnum, idx + aligned_rnum, sizeof(int) * aligned_padding);
 			memmove(idx + aligned_padding, idx, sizeof(int) * aligned_rnum);
 			memcpy(idx, idx + categorizeds->rnum, sizeof(int) * aligned_padding);
 			gsl_ran_shuffle(rng, idx + aligned_padding, aligned_rnum, sizeof(int));
 		}
 	}
 	ccfree(idx);
 	ccv_convnet_free(momentum);
 	ccv_convnet_free(update_params);
 	gsl_rng_free(rng);
 #ifdef HAVE_CUDA
 	}
 #endif
 #else
 	assert(0 && "ccv_convnet_supervised_train requires GSL library support");
 #endif
 }
 
diff --git a/lib/ccv_icf.c b/lib/ccv_icf.c
index 340eaab..5b54f92 100644
--- a/lib/ccv_icf.c
+++ b/lib/ccv_icf.c
@@ -2158,128 +2158,128 @@ static void _ccv_icf_detect_objects_with_multiscale_classifier_cascade(ccv_dense
 ccv_array_t* ccv_icf_detect_objects(ccv_dense_matrix_t* a, void* cascade, int count, ccv_icf_param_t params)
 {
 	assert(count > 0);
 	int i, j, k;
 	int type = *(((int**)cascade)[0]);
 	for (i = 1; i < count; i++)
 	{
 		// check all types to be the same
 		assert(*(((int**)cascade)[i]) == type);
 	}
 	ccv_array_t** seq = (ccv_array_t**)alloca(sizeof(ccv_array_t*) * count);
 	for (i = 0; i < count; i++)
 		seq[i] = ccv_array_new(sizeof(ccv_comp_t), 64, 0);
 	switch (type)
 	{
 		case CCV_ICF_CLASSIFIER_TYPE_A:
 			_ccv_icf_detect_objects_with_classifier_cascade(a, (ccv_icf_classifier_cascade_t**)cascade, count, params, seq);
 			break;
 		case CCV_ICF_CLASSIFIER_TYPE_B:
 			_ccv_icf_detect_objects_with_multiscale_classifier_cascade(a, (ccv_icf_multiscale_classifier_cascade_t**)cascade, count, params, seq);
 			break;
 	}
 	ccv_array_t* result_seq = ccv_array_new(sizeof(ccv_comp_t), 64, 0);
 	ccv_array_t* seq2 = ccv_array_new(sizeof(ccv_comp_t), 64, 0);
 	for (k = 0; k < count; k++)
 	{
 		/* the following code from OpenCV's haar feature implementation */
 		if(params.min_neighbors == 0)
 		{
 			for (i = 0; i < seq[k]->rnum; i++)
 			{
 				ccv_comp_t* comp = (ccv_comp_t*)ccv_array_get(seq[k], i);
 				ccv_array_push(result_seq, comp);
 			}
 		} else {
 			ccv_array_t* idx_seq = 0;
 			ccv_array_clear(seq2);
 			// group retrieved rectangles in order to filter out noise
 			int ncomp = ccv_array_group(seq[k], &idx_seq, _ccv_is_equal_same_class, 0);
-			ccv_comp_t* comps = (ccv_comp_t*)cccalloc(sizeof(ccv_comp_t), ncomp + 1);
+			ccv_comp_t* comps = (ccv_comp_t*)cccalloc(ncomp + 1, sizeof(ccv_comp_t));
 
 			// count number of neighbors
 			for (i = 0; i < seq[k]->rnum; i++)
 			{
 				ccv_comp_t r1 = *(ccv_comp_t*)ccv_array_get(seq[k], i);
 				int idx = *(int*)ccv_array_get(idx_seq, i);
 
 				comps[idx].classification.id = r1.classification.id;
 				if (r1.classification.confidence > comps[idx].classification.confidence || comps[idx].neighbors == 0)
 				{
 					comps[idx].rect = r1.rect;
 					comps[idx].classification.confidence = r1.classification.confidence;
 				}
 
 				++comps[idx].neighbors;
 			}
 
 			// calculate average bounding box
 			for (i = 0; i < ncomp; i++)
 			{
 				int n = comps[i].neighbors;
 				if (n >= params.min_neighbors)
 					ccv_array_push(seq2, comps + i);
 			}
 
 			// filter out large object rectangles contains small object rectangles
 			for (i = 0; i < seq2->rnum; i++)
 			{
 				ccv_comp_t* r2 = (ccv_comp_t*)ccv_array_get(seq2, i);
 				int distance = (int)(ccv_min(r2->rect.width, r2->rect.height) * 0.25 + 0.5);
 				for (j = 0; j < seq2->rnum; j++)
 				{
 					ccv_comp_t r1 = *(ccv_comp_t*)ccv_array_get(seq2, j);
 					if (i != j &&
 						abs(r1.classification.id) == r2->classification.id &&
 						r1.rect.x >= r2->rect.x - distance &&
 						r1.rect.y >= r2->rect.y - distance &&
 						r1.rect.x + r1.rect.width <= r2->rect.x + r2->rect.width + distance &&
 						r1.rect.y + r1.rect.height <= r2->rect.y + r2->rect.height + distance &&
 						// if r1 (the smaller one) is better, mute r2
 						(r2->classification.confidence <= r1.classification.confidence && r2->neighbors < r1.neighbors))
 					{
 						r2->classification.id = -r2->classification.id;
 						break;
 					}
 				}
 			}
 
 			// filter out small object rectangles inside large object rectangles
 			for (i = 0; i < seq2->rnum; i++)
 			{
 				ccv_comp_t r1 = *(ccv_comp_t*)ccv_array_get(seq2, i);
 				if (r1.classification.id > 0)
 				{
 					int flag = 1;
 
 					for (j = 0; j < seq2->rnum; j++)
 					{
 						ccv_comp_t r2 = *(ccv_comp_t*)ccv_array_get(seq2, j);
 						int distance = (int)(ccv_min(r2.rect.width, r2.rect.height) * 0.25 + 0.5);
 
 						if (i != j &&
 							abs(r1.classification.id) == abs(r2.classification.id) &&
 							r1.rect.x >= r2.rect.x - distance &&
 							r1.rect.y >= r2.rect.y - distance &&
 							r1.rect.x + r1.rect.width <= r2.rect.x + r2.rect.width + distance &&
 							r1.rect.y + r1.rect.height <= r2.rect.y + r2.rect.height + distance &&
 							// if r2 is better, we mute r1
 							(r2.classification.confidence > r1.classification.confidence || r2.neighbors >= r1.neighbors))
 						{
 							flag = 0;
 							break;
 						}
 					}
 
 					if (flag)
 						ccv_array_push(result_seq, &r1);
 				}
 			}
 			ccv_array_free(idx_seq);
 			ccfree(comps);
 		}
 		ccv_array_free(seq[k]);
 	}
 	ccv_array_free(seq2);
 
 	return result_seq;
 }